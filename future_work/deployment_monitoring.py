# å·®åˆ†éš±ç§è¯é‚¦å­¸ç¿’ç”Ÿç”¢ç’°å¢ƒéƒ¨ç½²èˆ‡ç›£æ§ç³»çµ±

import tensorflow as tf
import numpy as np
import pandas as pd
from datetime import datetime, timedelta
import json
import os
import logging
from typing import Dict, List, Optional, Tuple
import asyncio
from concurrent.futures import ThreadPoolExecutor
import hashlib
import pickle

# ======================== ç”Ÿç”¢ç’°å¢ƒéƒ¨ç½²ç®¡ç†å™¨ ========================

class DPFLProductionDeployment:
    """
    å·®åˆ†éš±ç§è¯é‚¦å­¸ç¿’ç”Ÿç”¢ç’°å¢ƒéƒ¨ç½²ç®¡ç†å™¨
    """
    
    def __init__(self, model_path: str, config_path: str, 
                 log_dir: str = "./production_logs"):
        self.model_path = model_path
        self.config_path = config_path
        self.log_dir = log_dir
        
        # åˆå§‹åŒ–æ—¥èªŒ
        self._setup_logging()
        
        # è¼‰å…¥æ¨¡å‹å’Œé…ç½®
        self.model = self._load_model()
        self.config = self._load_config()
        self.scalers = self._load_scalers()
        
        # æ€§èƒ½ç›£æ§
        self.performance_monitor = PerformanceMonitor()
        
        # éš±ç§é ç®—è¿½è¹¤å™¨
        self.privacy_tracker = ProductionPrivacyTracker(
            initial_budget=self.config.get('remaining_privacy_budget', 10.0)
        )
        
    def _setup_logging(self):
        """è¨­ç½®ç”Ÿç”¢ç’°å¢ƒæ—¥èªŒ"""
        os.makedirs(self.log_dir, exist_ok=True)
        
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(f"{self.log_dir}/dpfl_production.log"),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger('DPFLProduction')
        
    def _load_model(self) -> tf.keras.Model:
        """è¼‰å…¥è¨“ç·´å¥½çš„æ¨¡å‹"""
        try:
            model = tf.keras.models.load_model(self.model_path)
            self.logger.info(f"æ¨¡å‹è¼‰å…¥æˆåŠŸ: {self.model_path}")
            return model
        except Exception as e:
            self.logger.error(f"æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")
            raise
            
    def _load_config(self) -> Dict:
        """è¼‰å…¥é…ç½®"""
        try:
            # å˜—è©¦è¼‰å…¥å…ƒæ•¸æ“š
            metadata_path = self.model_path.replace('.keras', '_metadata.json')
            if os.path.exists(metadata_path):
                with open(metadata_path, 'r') as f:
                    config = json.load(f)
            else:
                with open(self.config_path, 'r') as f:
                    config = json.load(f)
            return config
        except Exception as e:
            self.logger.error(f"é…ç½®è¼‰å…¥å¤±æ•—: {e}")
            return {}
            
    def _load_scalers(self) -> Dict:
        """è¼‰å…¥ç¸®æ”¾å™¨"""
        try:
            artifacts_path = self.config_path.replace('.json', '_artifacts.pkl')
            with open(artifacts_path, 'rb') as f:
                artifacts = pickle.load(f)
            return {
                'feature_scaler': artifacts['feature_scaler'],
                'target_scaler': artifacts['target_scaler']
            }
        except Exception as e:
            self.logger.error(f"ç¸®æ”¾å™¨è¼‰å…¥å¤±æ•—: {e}")
            return {}
            
    async def predict_async(self, features: np.ndarray) -> np.ndarray:
        """ç•°æ­¥é æ¸¬"""
        loop = asyncio.get_event_loop()
        
        # åœ¨ç·šç¨‹æ± ä¸­åŸ·è¡Œé æ¸¬
        with ThreadPoolExecutor() as executor:
            # ç¸®æ”¾è¼¸å…¥
            scaled_features = await loop.run_in_executor(
                executor,
                self.scalers['feature_scaler'].transform,
                features
            )
            
            # é æ¸¬
            scaled_predictions = await loop.run_in_executor(
                executor,
                self.model.predict,
                scaled_features,
                {'verbose': 0}
            )
            
            # åç¸®æ”¾
            predictions = await loop.run_in_executor(
                executor,
                self.scalers['target_scaler'].inverse_transform,
                scaled_predictions
            )
            
        return predictions
        
    def predict_batch(self, features_list: List[np.ndarray],
                     add_noise: bool = True) -> List[float]:
        """
        æ‰¹é‡é æ¸¬withéš±ç§ä¿è­·
        """
        predictions = []
        
        for features in features_list:
            try:
                # æ€§èƒ½ç›£æ§
                start_time = datetime.now()
                
                # ç¸®æ”¾
                scaled_features = self.scalers['feature_scaler'].transform(
                    features.reshape(1, -1)
                )
                
                # é æ¸¬
                scaled_pred = self.model.predict(scaled_features, verbose=0)
                
                # åç¸®æ”¾
                pred = self.scalers['target_scaler'].inverse_transform(scaled_pred)
                
                # æ·»åŠ éš±ç§å™ªéŸ³ï¼ˆç”Ÿç”¢ç’°å¢ƒï¼‰
                if add_noise:
                    noise_scale = 0.01  # å°é‡å™ªéŸ³ä¿è­·è¼¸å‡ºéš±ç§
                    noise = np.random.laplace(0, noise_scale)
                    pred = pred + noise
                    
                predictions.append(float(pred[0, 0]))
                
                # è¨˜éŒ„æ€§èƒ½
                inference_time = (datetime.now() - start_time).total_seconds()
                self.performance_monitor.record_inference(inference_time)
                
            except Exception as e:
                self.logger.error(f"é æ¸¬éŒ¯èª¤: {e}")
                predictions.append(None)
                
        return predictions
        
    def update_model_incremental(self, new_model_path: str) -> bool:
        """
        å¢é‡æ›´æ–°æ¨¡å‹ï¼ˆä¿æŒéš±ç§é ç®—ï¼‰
        """
        try:
            # é©—è­‰æ–°æ¨¡å‹
            new_model = tf.keras.models.load_model(new_model_path)
            
            # æª¢æŸ¥æ¨¡å‹æ¶æ§‹ä¸€è‡´æ€§
            if not self._validate_model_architecture(new_model):
                raise ValueError("æ¨¡å‹æ¶æ§‹ä¸ä¸€è‡´")
                
            # å‚™ä»½ç•¶å‰æ¨¡å‹
            backup_path = f"{self.model_path}.backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            self.model.save(backup_path)
            
            # æ›´æ–°æ¨¡å‹
            self.model = new_model
            self.logger.info(f"æ¨¡å‹æ›´æ–°æˆåŠŸï¼Œå‚™ä»½ä¿å­˜è‡³: {backup_path}")
            
            return True
            
        except Exception as e:
            self.logger.error(f"æ¨¡å‹æ›´æ–°å¤±æ•—: {e}")
            return False
            
    def _validate_model_architecture(self, new_model: tf.keras.Model) -> bool:
        """é©—è­‰æ¨¡å‹æ¶æ§‹ä¸€è‡´æ€§"""
        return (new_model.input_shape == self.model.input_shape and
                new_model.output_shape == self.model.output_shape)

# ======================== æ€§èƒ½ç›£æ§å™¨ ========================

class PerformanceMonitor:
    """
    ç”Ÿç”¢ç’°å¢ƒæ€§èƒ½ç›£æ§
    """
    
    def __init__(self, window_size: int = 1000):
        self.window_size = window_size
        self.inference_times = []
        self.prediction_values = []
        self.timestamps = []
        
    def record_inference(self, inference_time: float, 
                        prediction: Optional[float] = None):
        """è¨˜éŒ„æ¨è«–æ€§èƒ½"""
        self.inference_times.append(inference_time)
        self.timestamps.append(datetime.now())
        
        if prediction is not None:
            self.prediction_values.append(prediction)
            
        # ä¿æŒçª—å£å¤§å°
        if len(self.inference_times) > self.window_size:
            self.inference_times.pop(0)
            self.timestamps.pop(0)
            if self.prediction_values:
                self.prediction_values.pop(0)
                
    def get_performance_stats(self) -> Dict[str, float]:
        """ç²å–æ€§èƒ½çµ±è¨ˆ"""
        if not self.inference_times:
            return {}
            
        return {
            'avg_inference_time': np.mean(self.inference_times),
            'p50_inference_time': np.percentile(self.inference_times, 50),
            'p95_inference_time': np.percentile(self.inference_times, 95),
            'p99_inference_time': np.percentile(self.inference_times, 99),
            'throughput': len(self.inference_times) / sum(self.inference_times),
            'total_predictions': len(self.inference_times)
        }
        
    def check_performance_degradation(self, threshold: float = 2.0) -> bool:
        """æª¢æŸ¥æ€§èƒ½æ˜¯å¦ä¸‹é™"""
        if len(self.inference_times) < 100:
            return False
            
        recent_avg = np.mean(self.inference_times[-100:])
        overall_avg = np.mean(self.inference_times)
        
        return recent_avg > overall_avg * threshold

# ======================== ç”Ÿç”¢ç’°å¢ƒéš±ç§è¿½è¹¤å™¨ ========================

class ProductionPrivacyTracker:
    """
    ç”Ÿç”¢ç’°å¢ƒéš±ç§é ç®—è¿½è¹¤
    """
    
    def __init__(self, initial_budget: float):
        self.total_budget = initial_budget
        self.consumed_budget = 0.0
        self.query_history = []
        
    def can_process_query(self, estimated_cost: float) -> bool:
        """æª¢æŸ¥æ˜¯å¦å¯ä»¥è™•ç†æŸ¥è©¢"""
        return self.consumed_budget + estimated_cost <= self.total_budget
        
    def record_query(self, query_type: str, privacy_cost: float):
        """è¨˜éŒ„æŸ¥è©¢å’Œéš±ç§æ¶ˆè€—"""
        self.consumed_budget += privacy_cost
        self.query_history.append({
            'timestamp': datetime.now(),
            'query_type': query_type,
            'privacy_cost': privacy_cost,
            'cumulative_cost': self.consumed_budget
        })
        
    def get_remaining_budget(self) -> float:
        """ç²å–å‰©é¤˜éš±ç§é ç®—"""
        return self.total_budget - self.consumed_budget
        
    def get_budget_report(self) -> Dict:
        """ç”Ÿæˆéš±ç§é ç®—å ±å‘Š"""
        return {
            'total_budget': self.total_budget,
            'consumed_budget': self.consumed_budget,
            'remaining_budget': self.get_remaining_budget(),
            'utilization_percent': (self.consumed_budget / self.total_budget) * 100,
            'total_queries': len(self.query_history),
            'avg_cost_per_query': self.consumed_budget / len(self.query_history) if self.query_history else 0
        }

# ======================== è¯é‚¦å­¸ç¿’å”èª¿å™¨ ========================

class FederatedCoordinator:
    """
    ç”Ÿç”¢ç’°å¢ƒè¯é‚¦å­¸ç¿’å”èª¿å™¨
    """
    
    def __init__(self, num_clients: int, min_clients: int = 3):
        self.num_clients = num_clients
        self.min_clients = min_clients
        self.client_registry = {}
        self.training_rounds = []
        
    def register_client(self, client_id: str, client_info: Dict) -> bool:
        """è¨»å†Šå®¢æˆ¶ç«¯"""
        try:
            self.client_registry[client_id] = {
                'info': client_info,
                'last_seen': datetime.now(),
                'participation_count': 0,
                'average_data_size': client_info.get('data_size', 0)
            }
            return True
        except Exception as e:
            logging.error(f"å®¢æˆ¶ç«¯è¨»å†Šå¤±æ•—: {e}")
            return False
            
    def select_clients(self, num_to_select: int) -> List[str]:
        """é¸æ“‡åƒèˆ‡è¨“ç·´çš„å®¢æˆ¶ç«¯"""
        # éæ¿¾æ´»èºå®¢æˆ¶ç«¯
        active_clients = [
            client_id for client_id, info in self.client_registry.items()
            if (datetime.now() - info['last_seen']).seconds < 300  # 5åˆ†é˜å…§æ´»èº
        ]
        
        if len(active_clients) < self.min_clients:
            logging.warning(f"æ´»èºå®¢æˆ¶ç«¯ä¸è¶³: {len(active_clients)} < {self.min_clients}")
            return []
            
        # åŸºæ–¼æ•¸æ“šé‡çš„åŠ æ¬Šæ¡æ¨£
        weights = [
            self.client_registry[cid]['average_data_size'] 
            for cid in active_clients
        ]
        
        if sum(weights) > 0:
            probs = np.array(weights) / sum(weights)
        else:
            probs = None
            
        selected = np.random.choice(
            active_clients,
            size=min(num_to_select, len(active_clients)),
            replace=False,
            p=probs
        )
        
        return selected.tolist()
        
    def aggregate_updates(self, client_updates: Dict[str, np.ndarray]) -> np.ndarray:
        """èšåˆå®¢æˆ¶ç«¯æ›´æ–°"""
        # ç²å–å®¢æˆ¶ç«¯æ¬Šé‡
        weights = []
        updates = []
        
        for client_id, update in client_updates.items():
            client_data_size = self.client_registry[client_id]['average_data_size']
            weights.append(client_data_size)
            updates.append(update)
            
        # åŠ æ¬Šå¹³å‡
        weights = np.array(weights) / sum(weights)
        aggregated = sum(w * u for w, u in zip(weights, updates))
        
        return aggregated

# ======================== å®‰å…¨é€šä¿¡ç®¡ç†å™¨ ========================

class SecureCommunicationManager:
    """
    å®‰å…¨é€šä¿¡ç®¡ç†å™¨
    """
    
    def __init__(self, encryption_key: Optional[bytes] = None):
        self.encryption_key = encryption_key or os.urandom(32)
        
    def encrypt_model_update(self, update: np.ndarray) -> bytes:
        """åŠ å¯†æ¨¡å‹æ›´æ–°"""
        # ç°¡åŒ–ç¤ºä¾‹ï¼šå¯¦éš›æ‡‰ä½¿ç”¨é©ç•¶çš„åŠ å¯†åº«
        update_bytes = pickle.dumps(update)
        
        # æ·»åŠ é›œæ¹Šé©—è­‰
        hash_value = hashlib.sha256(update_bytes).digest()
        
        # çµ„åˆæ•¸æ“š
        encrypted_data = hash_value + update_bytes
        
        return encrypted_data
        
    def decrypt_model_update(self, encrypted_data: bytes) -> np.ndarray:
        """è§£å¯†æ¨¡å‹æ›´æ–°"""
        # æå–é›œæ¹Šå’Œæ•¸æ“š
        hash_value = encrypted_data[:32]
        update_bytes = encrypted_data[32:]
        
        # é©—è­‰å®Œæ•´æ€§
        if hashlib.sha256(update_bytes).digest() != hash_value:
            raise ValueError("æ•¸æ“šå®Œæ•´æ€§é©—è­‰å¤±æ•—")
            
        # è§£å¯†
        update = pickle.loads(update_bytes)
        
        return update

# ======================== è‡ªå‹•åŒ–é‹ç¶­ç³»çµ± ========================

class AutomatedOpsManager:
    """
    è‡ªå‹•åŒ–é‹ç¶­ç®¡ç†å™¨
    """
    
    def __init__(self, deployment: DPFLProductionDeployment):
        self.deployment = deployment
        self.health_checks = []
        self.alert_thresholds = {
            'inference_time_p95': 0.1,  # 100ms
            'privacy_budget_remaining': 0.1,  # 10%
            'error_rate': 0.05  # 5%
        }
        
    async def health_check(self) -> Dict[str, any]:
        """åŸ·è¡Œå¥åº·æª¢æŸ¥"""
        health_status = {
            'timestamp': datetime.now().isoformat(),
            'model_status': 'healthy',
            'performance_status': 'healthy',
            'privacy_status': 'healthy',
            'issues': []
        }
        
        # æª¢æŸ¥æ¨¡å‹
        try:
            test_input = np.random.randn(1, 13)
            _ = await self.deployment.predict_async(test_input)
        except Exception as e:
            health_status['model_status'] = 'unhealthy'
            health_status['issues'].append(f"æ¨¡å‹é æ¸¬å¤±æ•—: {e}")
            
        # æª¢æŸ¥æ€§èƒ½
        perf_stats = self.deployment.performance_monitor.get_performance_stats()
        if perf_stats.get('p95_inference_time', 0) > self.alert_thresholds['inference_time_p95']:
            health_status['performance_status'] = 'degraded'
            health_status['issues'].append("æ¨è«–å»¶é²éé«˜")
            
        # æª¢æŸ¥éš±ç§é ç®—
        privacy_report = self.deployment.privacy_tracker.get_budget_report()
        remaining_percent = privacy_report['remaining_budget'] / privacy_report['total_budget']
        if remaining_percent < self.alert_thresholds['privacy_budget_remaining']:
            health_status['privacy_status'] = 'critical'
            health_status['issues'].append("éš±ç§é ç®—å³å°‡è€—ç›¡")
            
        self.health_checks.append(health_status)
        
        return health_status
        
    def auto_scale_decision(self) -> Dict[str, any]:
        """è‡ªå‹•æ“´ç¸®å®¹æ±ºç­–"""
        perf_stats = self.deployment.performance_monitor.get_performance_stats()
        
        # åŸºæ–¼æ€§èƒ½æŒ‡æ¨™çš„æ“´ç¸®å®¹å»ºè­°
        if perf_stats.get('p95_inference_time', 0) > 0.2:  # 200ms
            return {
                'action': 'scale_up',
                'reason': 'æ¨è«–å»¶é²éé«˜',
                'recommended_instances': 2
            }
        elif perf_stats.get('throughput', float('inf')) < 10:  # 10 req/s
            return {
                'action': 'scale_up',
                'reason': 'ååé‡ä¸è¶³',
                'recommended_instances': 1
            }
        elif perf_stats.get('avg_inference_time', 0) < 0.01:  # 10ms
            return {
                'action': 'scale_down',
                'reason': 'è³‡æºåˆ©ç”¨ç‡ä½',
                'recommended_instances': -1
            }
        else:
            return {
                'action': 'maintain',
                'reason': 'æ€§èƒ½æ­£å¸¸'
            }

# ======================== éƒ¨ç½²è…³æœ¬ç¯„ä¾‹ ========================

async def deploy_production_system():
    """
    éƒ¨ç½²ç”Ÿç”¢ç³»çµ±ç¯„ä¾‹
    """
    # åˆå§‹åŒ–éƒ¨ç½²
    deployment = DPFLProductionDeployment(
        model_path='federated_coloran_model_dp.keras',
        config_path='dpfl_config.json'
    )
    
    # åˆå§‹åŒ–å”èª¿å™¨
    coordinator = FederatedCoordinator(num_clients=7)
    
    # åˆå§‹åŒ–é‹ç¶­ç®¡ç†å™¨
    ops_manager = AutomatedOpsManager(deployment)
    
    # å•Ÿå‹•å¥åº·æª¢æŸ¥å¾ªç’°
    async def health_check_loop():
        while True:
            health_status = await ops_manager.health_check()
            if health_status['issues']:
                logging.warning(f"å¥åº·æª¢æŸ¥ç™¼ç¾å•é¡Œ: {health_status['issues']}")
            await asyncio.sleep(60)  # æ¯åˆ†é˜æª¢æŸ¥
            
    # å•Ÿå‹•è‡ªå‹•æ“´ç¸®å®¹å¾ªç’°
    async def auto_scale_loop():
        while True:
            scale_decision = ops_manager.auto_scale_decision()
            if scale_decision['action'] != 'maintain':
                logging.info(f"æ“´ç¸®å®¹å»ºè­°: {scale_decision}")
            await asyncio.sleep(300)  # æ¯5åˆ†é˜è©•ä¼°
            
    # ä¸¦è¡ŒåŸ·è¡Œ
    await asyncio.gather(
        health_check_loop(),
        auto_scale_loop()
    )

# ======================== ç›£æ§å„€è¡¨æ¿ ========================

def create_monitoring_dashboard(deployment: DPFLProductionDeployment):
    """
    å‰µå»ºç›£æ§å„€è¡¨æ¿
    """
    import matplotlib.pyplot as plt
    from matplotlib.animation import FuncAnimation
    
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))
    fig.suptitle('DP-FL Production Monitoring Dashboard', fontsize=16)
    
    def update_dashboard(frame):
        # æ¸…ç©ºåœ–è¡¨
        for ax in axes.flat:
            ax.clear()
            
        # 1. æ¨è«–å»¶é²
        perf_stats = deployment.performance_monitor.get_performance_stats()
        if deployment.performance_monitor.inference_times:
            axes[0, 0].hist(deployment.performance_monitor.inference_times[-100:], 
                          bins=20, alpha=0.7, color='blue')
            axes[0, 0].axvline(perf_stats.get('p95_inference_time', 0), 
                              color='red', linestyle='--', label='P95')
            axes[0, 0].set_xlabel('Inference Time (s)')
            axes[0, 0].set_ylabel('Frequency')
            axes[0, 0].set_title('Inference Latency Distribution')
            axes[0, 0].legend()
            
        # 2. ååé‡è¶¨å‹¢
        if deployment.performance_monitor.timestamps:
            # è¨ˆç®—æ¯åˆ†é˜ååé‡
            current_time = datetime.now()
            one_minute_ago = current_time - timedelta(minutes=1)
            recent_timestamps = [
                ts for ts in deployment.performance_monitor.timestamps 
                if ts > one_minute_ago
            ]
            throughput = len(recent_timestamps) / 60.0
            
            axes[0, 1].text(0.5, 0.5, f'{throughput:.1f}\nrequests/sec',
                          ha='center', va='center', fontsize=24)
            axes[0, 1].set_title('Current Throughput')
            axes[0, 1].axis('off')
            
        # 3. éš±ç§é ç®—ä½¿ç”¨
        privacy_report = deployment.privacy_tracker.get_budget_report()
        consumed = privacy_report['consumed_budget']
        remaining = privacy_report['remaining_budget']
        
        axes[1, 0].pie([consumed, remaining], 
                      labels=['Consumed', 'Remaining'],
                      colors=['red', 'green'],
                      autopct='%1.1f%%',
                      startangle=90)
        axes[1, 0].set_title('Privacy Budget Status')
        
        # 4. ç³»çµ±å¥åº·ç‹€æ…‹
        ax = axes[1, 1]
        health_indicators = {
            'Model': 'green',
            'Performance': 'green' if perf_stats.get('p95_inference_time', 0) < 0.1 else 'yellow',
            'Privacy': 'green' if remaining > 0.2 * privacy_report['total_budget'] else 'red',
            'System': 'green'
        }
        
        y_pos = np.arange(len(health_indicators))
        colors = list(health_indicators.values())
        
        ax.barh(y_pos, [1]*len(health_indicators), color=colors, alpha=0.7)
        ax.set_yticks(y_pos)
        ax.set_yticklabels(health_indicators.keys())
        ax.set_xlim(0, 1)
        ax.set_title('System Health Status')
        ax.set_xticks([])
        
        plt.tight_layout()
        
    # å‹•ç•«æ›´æ–°
    ani = FuncAnimation(fig, update_dashboard, interval=5000)  # æ¯5ç§’æ›´æ–°
    plt.show()

# ======================== ä¸»å‡½æ•¸ ========================

if __name__ == "__main__":
    # ç”Ÿç”¢ç’°å¢ƒéƒ¨ç½²ç¤ºä¾‹
    print("ğŸš€ å•Ÿå‹•å·®åˆ†éš±ç§è¯é‚¦å­¸ç¿’ç”Ÿç”¢ç³»çµ±...")
    
    # é‹è¡Œç•°æ­¥éƒ¨ç½²
    # asyncio.run(deploy_production_system())
    
    # æˆ–è€…å‰µå»ºç›£æ§å„€è¡¨æ¿
    # deployment = DPFLProductionDeployment(...)
    # create_monitoring_dashboard(deployment)